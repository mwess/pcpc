What does #pragma parallel for do?
=> runs the following code in several threads (number defined by system, can be changed by "export ...") and divide the work of the for loop among the threads

What is the problem of data or loop dependence?
=> Cant be parallelized because we need the newly calculated data for further calculations

Run the parallel for directive with more than 1 thread. What might go wrong?
=> its possible to read values that have not been set yet

How can you fix this without modifying the computation logic, i.e. using OpenMP fea-
tures?
=> change execution to "pragma omp ordered" (and "#pragma omp parallel for ordered" before needed)


Modify the program logic such that the program behaves correctly with multiple
threads. Use the schedule clause to show how the iterations are divided among
threads.
=> you could divide the calculations into smaller subsets and multiply them in the end
